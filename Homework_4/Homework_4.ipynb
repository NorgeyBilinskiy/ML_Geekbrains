{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENiWYl_EtWcm"
      },
      "source": [
        "### 1. Загрузите тренировочные и тестовые датасеты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "_uf-KNwQtWcn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import PolynomialFeatures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размер датасета: (5567, 15)\n",
            "Пропущенные значения:\n",
            "f1        0\n",
            "f2        0\n",
            "f3        0\n",
            "f4        0\n",
            "f5        0\n",
            "f6        0\n",
            "f7        0\n",
            "f8        0\n",
            "f9        0\n",
            "f10       0\n",
            "f11       0\n",
            "f12       0\n",
            "f13       0\n",
            "f14       0\n",
            "target    0\n",
            "dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "      <th>f11</th>\n",
              "      <th>f12</th>\n",
              "      <th>f13</th>\n",
              "      <th>f14</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50</td>\n",
              "      <td>218.593930</td>\n",
              "      <td>273536</td>\n",
              "      <td>0.104575</td>\n",
              "      <td>4</td>\n",
              "      <td>0.445026</td>\n",
              "      <td>0.274531</td>\n",
              "      <td>0.444334</td>\n",
              "      <td>5.970149</td>\n",
              "      <td>0.300298</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>49</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32</td>\n",
              "      <td>276.771005</td>\n",
              "      <td>173314</td>\n",
              "      <td>0.224684</td>\n",
              "      <td>11</td>\n",
              "      <td>0.445026</td>\n",
              "      <td>0.439103</td>\n",
              "      <td>0.444334</td>\n",
              "      <td>5.970149</td>\n",
              "      <td>0.300298</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>0.244418</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>218.593930</td>\n",
              "      <td>28887</td>\n",
              "      <td>0.032491</td>\n",
              "      <td>7</td>\n",
              "      <td>0.445026</td>\n",
              "      <td>0.274531</td>\n",
              "      <td>0.444334</td>\n",
              "      <td>25.606721</td>\n",
              "      <td>0.300298</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>0.244418</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>19</td>\n",
              "      <td>218.593930</td>\n",
              "      <td>427862</td>\n",
              "      <td>0.179322</td>\n",
              "      <td>10</td>\n",
              "      <td>0.049127</td>\n",
              "      <td>0.044987</td>\n",
              "      <td>0.009499</td>\n",
              "      <td>25.606721</td>\n",
              "      <td>0.300298</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0.244418</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>44</td>\n",
              "      <td>218.593930</td>\n",
              "      <td>109339</td>\n",
              "      <td>0.032491</td>\n",
              "      <td>7</td>\n",
              "      <td>0.098837</td>\n",
              "      <td>0.115721</td>\n",
              "      <td>0.066581</td>\n",
              "      <td>5.970149</td>\n",
              "      <td>0.113590</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>0.185185</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7494</th>\n",
              "      <td>40</td>\n",
              "      <td>218.593930</td>\n",
              "      <td>120277</td>\n",
              "      <td>0.171817</td>\n",
              "      <td>9</td>\n",
              "      <td>0.049127</td>\n",
              "      <td>0.071672</td>\n",
              "      <td>0.009499</td>\n",
              "      <td>25.606721</td>\n",
              "      <td>0.300298</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0.249475</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7496</th>\n",
              "      <td>25</td>\n",
              "      <td>218.593930</td>\n",
              "      <td>104439</td>\n",
              "      <td>0.179322</td>\n",
              "      <td>10</td>\n",
              "      <td>0.049127</td>\n",
              "      <td>0.131370</td>\n",
              "      <td>0.103024</td>\n",
              "      <td>25.606721</td>\n",
              "      <td>0.113590</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>0.244418</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7497</th>\n",
              "      <td>50</td>\n",
              "      <td>218.593930</td>\n",
              "      <td>162632</td>\n",
              "      <td>0.171817</td>\n",
              "      <td>9</td>\n",
              "      <td>0.445026</td>\n",
              "      <td>0.482222</td>\n",
              "      <td>0.444334</td>\n",
              "      <td>25.606721</td>\n",
              "      <td>0.300298</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>0.244418</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7498</th>\n",
              "      <td>51</td>\n",
              "      <td>276.771005</td>\n",
              "      <td>174824</td>\n",
              "      <td>0.171817</td>\n",
              "      <td>9</td>\n",
              "      <td>0.049127</td>\n",
              "      <td>0.093897</td>\n",
              "      <td>0.103024</td>\n",
              "      <td>25.606721</td>\n",
              "      <td>0.300298</td>\n",
              "      <td>8614.0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0.244418</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7499</th>\n",
              "      <td>29</td>\n",
              "      <td>263.691684</td>\n",
              "      <td>180916</td>\n",
              "      <td>0.179322</td>\n",
              "      <td>10</td>\n",
              "      <td>0.066390</td>\n",
              "      <td>0.131370</td>\n",
              "      <td>0.066581</td>\n",
              "      <td>25.606721</td>\n",
              "      <td>0.113590</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0.244418</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5567 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      f1          f2      f3        f4  f5        f6        f7        f8  \\\n",
              "0     50  218.593930  273536  0.104575   4  0.445026  0.274531  0.444334   \n",
              "1     32  276.771005  173314  0.224684  11  0.445026  0.439103  0.444334   \n",
              "2     38  218.593930   28887  0.032491   7  0.445026  0.274531  0.444334   \n",
              "3     19  218.593930  427862  0.179322  10  0.049127  0.044987  0.009499   \n",
              "4     44  218.593930  109339  0.032491   7  0.098837  0.115721  0.066581   \n",
              "...   ..         ...     ...       ...  ..       ...       ...       ...   \n",
              "7494  40  218.593930  120277  0.171817   9  0.049127  0.071672  0.009499   \n",
              "7496  25  218.593930  104439  0.179322  10  0.049127  0.131370  0.103024   \n",
              "7497  50  218.593930  162632  0.171817   9  0.445026  0.482222  0.444334   \n",
              "7498  51  276.771005  174824  0.171817   9  0.049127  0.093897  0.103024   \n",
              "7499  29  263.691684  180916  0.179322  10  0.066390  0.131370  0.066581   \n",
              "\n",
              "             f9       f10     f11  f12  f13       f14  target  \n",
              "0      5.970149  0.300298     0.0    0   49  0.100000       0  \n",
              "1      5.970149  0.300298     0.0    0   60  0.244418       0  \n",
              "2     25.606721  0.300298     0.0    0   50  0.244418       0  \n",
              "3     25.606721  0.300298     0.0    0   35  0.244418       0  \n",
              "4      5.970149  0.113590     0.0    0   46  0.185185       0  \n",
              "...         ...       ...     ...  ...  ...       ...     ...  \n",
              "7494  25.606721  0.300298     0.0    0   40  0.249475       0  \n",
              "7496  25.606721  0.113590     0.0    0   50  0.244418       0  \n",
              "7497  25.606721  0.300298     0.0    0   45  0.244418       0  \n",
              "7498  25.606721  0.300298  8614.0    0   40  0.244418       1  \n",
              "7499  25.606721  0.113590     0.0    0   38  0.244418       0  \n",
              "\n",
              "[5567 rows x 15 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xtrain = pd.read_csv(\"TrainData.csv\")\n",
        "Xtrain = Xtrain.dropna()\n",
        "print(\"Размер датасета:\", Xtrain.shape)\n",
        "print(\"Пропущенные значения:\")\n",
        "print(Xtrain.isnull().sum())\n",
        "Xtrain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размер датасета: (2500, 15)\n",
            "Пропущенные значения:\n",
            "f1        0\n",
            "f2        0\n",
            "f3        0\n",
            "f4        0\n",
            "f5        0\n",
            "f6        0\n",
            "f7        0\n",
            "f8        0\n",
            "f9        0\n",
            "f10       0\n",
            "f11       0\n",
            "f12       0\n",
            "f13       0\n",
            "f14       0\n",
            "target    0\n",
            "dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "      <th>f11</th>\n",
              "      <th>f12</th>\n",
              "      <th>f13</th>\n",
              "      <th>f14</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31</td>\n",
              "      <td>238.933333</td>\n",
              "      <td>47296</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>10</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>23.893333</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0</td>\n",
              "      <td>1740</td>\n",
              "      <td>20</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24</td>\n",
              "      <td>238.933333</td>\n",
              "      <td>33088</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>7</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>23.893333</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18</td>\n",
              "      <td>238.933333</td>\n",
              "      <td>283342</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>7</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>23.893333</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>19</td>\n",
              "      <td>238.933333</td>\n",
              "      <td>393712</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>9</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>23.893333</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>238.933333</td>\n",
              "      <td>200515</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>10</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>23.893333</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2495</th>\n",
              "      <td>40</td>\n",
              "      <td>238.933333</td>\n",
              "      <td>220589</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>10</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>23.893333</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>54</td>\n",
              "      <td>238.933333</td>\n",
              "      <td>165278</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>10</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>23.893333</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2497</th>\n",
              "      <td>44</td>\n",
              "      <td>238.933333</td>\n",
              "      <td>398473</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>10</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>23.893333</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2498</th>\n",
              "      <td>35</td>\n",
              "      <td>238.933333</td>\n",
              "      <td>183898</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>11</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>23.893333</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>7298</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499</th>\n",
              "      <td>58</td>\n",
              "      <td>238.933333</td>\n",
              "      <td>98361</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>9</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>23.893333</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>0.238933</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2500 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      f1          f2      f3        f4  f5        f6        f7        f8  \\\n",
              "0     31  238.933333   47296  0.238933  10  0.238933  0.238933  0.238933   \n",
              "1     24  238.933333   33088  0.238933   7  0.238933  0.238933  0.238933   \n",
              "2     18  238.933333  283342  0.238933   7  0.238933  0.238933  0.238933   \n",
              "3     19  238.933333  393712  0.238933   9  0.238933  0.238933  0.238933   \n",
              "4     28  238.933333  200515  0.238933  10  0.238933  0.238933  0.238933   \n",
              "...   ..         ...     ...       ...  ..       ...       ...       ...   \n",
              "2495  40  238.933333  220589  0.238933  10  0.238933  0.238933  0.238933   \n",
              "2496  54  238.933333  165278  0.238933  10  0.238933  0.238933  0.238933   \n",
              "2497  44  238.933333  398473  0.238933  10  0.238933  0.238933  0.238933   \n",
              "2498  35  238.933333  183898  0.238933  11  0.238933  0.238933  0.238933   \n",
              "2499  58  238.933333   98361  0.238933   9  0.238933  0.238933  0.238933   \n",
              "\n",
              "             f9       f10   f11   f12  f13       f14  target  \n",
              "0     23.893333  0.238933     0  1740   20  0.238933       0  \n",
              "1     23.893333  0.238933     0     0   40  0.238933       0  \n",
              "2     23.893333  0.238933     0     0   20  0.238933       0  \n",
              "3     23.893333  0.238933     0     0   20  0.238933       0  \n",
              "4     23.893333  0.238933     0     0   40  0.238933       0  \n",
              "...         ...       ...   ...   ...  ...       ...     ...  \n",
              "2495  23.893333  0.238933     0     0   40  0.238933       1  \n",
              "2496  23.893333  0.238933     0     0   40  0.238933       1  \n",
              "2497  23.893333  0.238933     0     0   70  0.238933       1  \n",
              "2498  23.893333  0.238933  7298     0   50  0.238933       1  \n",
              "2499  23.893333  0.238933     0     0   50  0.238933       0  \n",
              "\n",
              "[2500 rows x 15 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xtest = pd.read_csv(\"TestData.csv\")\n",
        "print(\"Размер датасета:\", Xtest.shape)\n",
        "print(\"Пропущенные значения:\")\n",
        "print(Xtest.isnull().sum())\n",
        "Xtest\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQkpwQGHtWcr"
      },
      "source": [
        "### 2. Оцените баланс классов в задаче\n",
        "- Затем попытайтесь устно ответить на вопрос, можно ли использовать accuracy как метрику качества в задаче?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "csjvNCCutWcs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "target\n",
            "0    4238\n",
            "1    1329\n",
            "Name: count, dtype: int64\n",
            "target\n",
            "0    1913\n",
            "1     587\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(Xtrain['target'].value_counts())\n",
        "print(Xtest['target'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Дисбаланс классов значительный, метрика accuracy может быть не очень информативной. Это происходит из-за того, что модель может предсказывать большинство объектов как класс 0 и при этом показывать высокую точность, игнорируя меньшинство класса 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB_ReQ62tWct"
      },
      "source": [
        "### 3. Постройте baseline-модель:\n",
        "- разбейте TrainData на тренировочные (Train) и тестовые данные (Test);\n",
        "- обучите LogisticRegression и SVC с параметрами по умолчанию на тренировочных данных (Train);\n",
        "- примените модели на тестовых данных (Test)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "WUfRVj5ctWcu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.94      0.90       848\n",
            "           1       0.74      0.56      0.64       266\n",
            "\n",
            "    accuracy                           0.85      1114\n",
            "   macro avg       0.81      0.75      0.77      1114\n",
            "weighted avg       0.84      0.85      0.84      1114\n",
            "\n",
            "F1-мера для Logistic Regression: 0.8413\n",
            "\n",
            "\n",
            "SVC Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.91       848\n",
            "           1       0.77      0.54      0.63       266\n",
            "\n",
            "    accuracy                           0.85      1114\n",
            "   macro avg       0.82      0.74      0.77      1114\n",
            "weighted avg       0.84      0.85      0.84      1114\n",
            "\n",
            "F1-мера для SVC: 0.8415\n"
          ]
        }
      ],
      "source": [
        "X = Xtrain.drop('target', axis=1)  \n",
        "y = Xtrain['target']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "logreg = LogisticRegression(random_state=42)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred_logreg = logreg.predict(X_test)\n",
        "print(\"Logistic Regression Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_logreg))\n",
        "f1_logreg = f1_score(y_test, y_pred_logreg, average='weighted')\n",
        "print(f'F1-мера для Logistic Regression: {f1_logreg:.4f}')\n",
        "\n",
        "svc = SVC(random_state=42)\n",
        "svc.fit(X_train, y_train)\n",
        "y_pred_svc = svc.predict(X_test)\n",
        "print(\"\\n\\nSVC Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_svc))\n",
        "f1_svc = f1_score(y_test, y_pred_svc, average='weighted')\n",
        "print(f'F1-мера для SVC: {f1_svc:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYQnr8CftWcv"
      },
      "source": [
        "### 4. Улучшите модели\n",
        "Попробуйте улучшить качество обученных моделей:\n",
        "- можете задавать class_weights;\n",
        "- можете изменять параметры модели;\n",
        "- можете вручную или при помощи методов Python генерировать новые признаки и/или удалять существующие.\n",
        "\n",
        "Это самая важная и творческая часть задания. Проводите как можно больше экспериментов!\n",
        "\n",
        "Проведите минимиум три эксперимента: для каждого типа модели минимум один эксперимент."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### №1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZJrKNIw8tWcw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression (balanced) Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.80      0.87       848\n",
            "           1       0.58      0.88      0.69       266\n",
            "\n",
            "    accuracy                           0.82      1114\n",
            "   macro avg       0.76      0.84      0.78      1114\n",
            "weighted avg       0.86      0.82      0.83      1114\n",
            "\n",
            "F1-мера для Logistic Regression (balanced): 0.8268\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression с class_weight='balanced'\n",
        "logreg_balanced = LogisticRegression(random_state=42, class_weight='balanced')\n",
        "logreg_balanced.fit(X_train, y_train)\n",
        "y_pred_logreg_balanced = logreg_balanced.predict(X_test)\n",
        "\n",
        "print(\"Logistic Regression (balanced) Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_logreg_balanced))\n",
        "f1_logreg_balanced = f1_score(y_test, y_pred_logreg_balanced, average='weighted')\n",
        "print(f'F1-мера для Logistic Regression (balanced): {f1_logreg_balanced:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### №2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "SVC (optimized) Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.77      0.85       848\n",
            "           1       0.55      0.89      0.68       266\n",
            "\n",
            "    accuracy                           0.80      1114\n",
            "   macro avg       0.75      0.83      0.76      1114\n",
            "weighted avg       0.86      0.80      0.81      1114\n",
            "\n",
            "F1-мера для SVC: 0.8094\n"
          ]
        }
      ],
      "source": [
        "# SVC с class_weight='balanced' и изменёнными параметрами C и радиально-базисным ядром\n",
        "svc_optimized = SVC(random_state=42, class_weight='balanced', C=0.5, kernel='rbf')\n",
        "svc_optimized.fit(X_train, y_train)\n",
        "y_pred_svc_optimized = svc_optimized.predict(X_test)\n",
        "\n",
        "print(\"\\n\\nSVC (optimized) Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_svc_optimized))\n",
        "f1_svc_optimized = f1_score(y_test, y_pred_svc_optimized, average='weighted')\n",
        "print(f'F1-мера для SVC: {f1_svc_optimized:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### №3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Logistic Regression (polynomial features) Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.79      0.86       848\n",
            "           1       0.57      0.88      0.69       266\n",
            "\n",
            "    accuracy                           0.81      1114\n",
            "   macro avg       0.76      0.83      0.78      1114\n",
            "weighted avg       0.86      0.81      0.82      1114\n",
            "\n",
            "F1-мера для Logistic Regression (polynomial features): 0.8221\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression с полиномиальными признаками\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "X_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(X_poly, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "logreg_poly = LogisticRegression(random_state=42, class_weight='balanced')\n",
        "logreg_poly.fit(X_train_poly, y_train_poly)\n",
        "y_pred_logreg_poly = logreg_poly.predict(X_test_poly)\n",
        "\n",
        "print(\"\\n\\nLogistic Regression (polynomial features) Classification Report:\")\n",
        "print(classification_report(y_test_poly, y_pred_logreg_poly))\n",
        "f1_logreg_poly = f1_score(y_test_poly, y_pred_logreg_poly, average='weighted')\n",
        "print(f'F1-мера для Logistic Regression (polynomial features): {f1_logreg_poly:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### №4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "SVC (polynomial features) Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.77      0.85       848\n",
            "           1       0.54      0.85      0.66       266\n",
            "\n",
            "    accuracy                           0.79      1114\n",
            "   macro avg       0.74      0.81      0.75      1114\n",
            "weighted avg       0.85      0.79      0.80      1114\n",
            "\n",
            "F1-мера для SVC (polynomial features): 0.8037\n"
          ]
        }
      ],
      "source": [
        "# Обучение модели SVC с полиномиальными признаками\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
        "X_poly = poly.fit_transform(X)\n",
        "X_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(X_poly, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "svc_poly = SVC(random_state=42, class_weight='balanced')\n",
        "svc_poly.fit(X_train_poly, y_train_poly)\n",
        "y_pred_svc_poly = svc_poly.predict(X_test_poly)\n",
        "\n",
        "print(\"\\n\\nSVC (polynomial features) Classification Report:\")\n",
        "print(classification_report(y_test_poly, y_pred_svc_poly))\n",
        "f1_svc_poly = f1_score(y_test_poly, y_pred_svc_poly, average='weighted')\n",
        "print(f'F1-мера для SVC (polynomial features): {f1_svc_poly:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### №5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters:\n",
            "{'C': 1, 'gamma': 0.1}\n",
            "\n",
            "\n",
            "SVC (Grid Search) Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.78      0.86       848\n",
            "           1       0.55      0.88      0.68       266\n",
            "\n",
            "    accuracy                           0.80      1114\n",
            "   macro avg       0.75      0.83      0.77      1114\n",
            "weighted avg       0.86      0.80      0.81      1114\n",
            "\n",
            "F1-мера для SVC (Grid Search): 0.8141\n"
          ]
        }
      ],
      "source": [
        "# SVC с Grid Search\n",
        "svc = SVC(kernel='rbf', class_weight='balanced', random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100], #Параметр регуляризации\n",
        "    'gamma': [0.001, 0.01, 0.1, 1] #Параметр, который определяет радиус влияния одной обучающей точки.\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "y_pred_svc_grid = grid_search.predict(X_test)\n",
        "\n",
        "print(\"\\n\\nSVC (Grid Search) Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_svc_grid))\n",
        "f1_svc_grid = f1_score(y_test, y_pred_svc_grid, average='weighted')\n",
        "print(f'F1-мера для SVC (Grid Search): {f1_svc_grid:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfu3yy_7tWcy"
      },
      "source": [
        "### 5. Оцените на отложенной выборке качество наилучшей модели\n",
        "В пунктах 3 и 4 вы построили много разных моделей.\n",
        "\n",
        "Возьмите ту, которая дала наилучшее качество на тестовых данных (Test). Примените её на отложенной выборке (TestData) и выведите на экран значение метрики f1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "upHUOfrktWcy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Norge\\anaconda3\\envs\\data_parsing\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVC was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "SVC (Grid Search) Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      1.00      0.87      1913\n",
            "           1       1.00      0.00      0.00       587\n",
            "\n",
            "    accuracy                           0.77      2500\n",
            "   macro avg       0.88      0.50      0.43      2500\n",
            "weighted avg       0.82      0.77      0.66      2500\n",
            "\n",
            "F1-мера для SVC (Grid Search): 0.6634\n"
          ]
        }
      ],
      "source": [
        "X_T = Xtest.drop('target', axis=1)  \n",
        "y_T = Xtest['target']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X_T)\n",
        "\n",
        "y_pred_svc_grid = grid_search.predict(X_T)\n",
        "\n",
        "print(\"\\n\\nSVC (Grid Search) Classification Report:\")\n",
        "print(classification_report(y_T, y_pred_svc_grid, zero_division=1))\n",
        "f1_svc_grid = f1_score(y_T, y_pred_svc_grid, average='weighted', zero_division=1)\n",
        "print(f'F1-мера для SVC (Grid Search): {f1_svc_grid:.4f}')\n"
      ]
    },
    {
      "attachments": {
        "image.png": {
          "image/png": "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"
        }
      },
      "cell_type": "markdown",
      "metadata": {
        "id": "YZT0rMuStWcz"
      },
      "source": [
        "### 6. Выполните хитрый трюк\n",
        "Часто смешивание различных моделей даёт улучшение итогового предсказания. Попробуйте смешать две лучшие модели по формуле:\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "Значение $\\alpha$ подберите в цикле по Test-выборке. Оцените качество на отложенной выборке.\n",
        "\n",
        "Удалось ли добиться улучшения качества?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "3DdSsk6gtWc7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Norge\\anaconda3\\envs\\data_parsing\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\Norge\\anaconda3\\envs\\data_parsing\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVC was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alpha: 0.0 - F1-мера: 0.6634\n",
            "Alpha: 0.1 - F1-мера: 0.6634\n",
            "Alpha: 0.2 - F1-мера: 0.6634\n",
            "Alpha: 0.3 - F1-мера: 0.6634\n",
            "Alpha: 0.4 - F1-мера: 0.6634\n",
            "Alpha: 0.5 - F1-мера: 0.6634\n",
            "Alpha: 0.6 - F1-мера: 0.0893\n",
            "Alpha: 0.7 - F1-мера: 0.0893\n",
            "Alpha: 0.8 - F1-мера: 0.0893\n",
            "Alpha: 0.9 - F1-мера: 0.0893\n",
            "Alpha: 1.0 - F1-мера: 0.0893\n",
            "\n",
            "Лучшее значение Alpha: 0.0\n",
            "Лучшая F1-мера: 0.6634\n"
          ]
        }
      ],
      "source": [
        "y_pred_logreg = logreg.predict(X_T)\n",
        "y_pred_svc_grid = grid_search.predict(X_T)\n",
        "\n",
        "alpha_values = np.linspace(0, 1, 11)\n",
        "\n",
        "best_alpha = None\n",
        "best_f1 = 0\n",
        "\n",
        "for alpha in alpha_values:\n",
        "    # Смешиваем предсказания\n",
        "    y_pred_final = (alpha * y_pred_logreg + (1 - alpha) * y_pred_svc_grid).round().astype(int)\n",
        "    f1_final = f1_score(y_T, y_pred_final, average='weighted')\n",
        "    print(f'Alpha: {alpha:.1f} - F1-мера: {f1_final:.4f}')\n",
        "    # Сохраняем лучшее значение alpha\n",
        "    if f1_final > best_f1:\n",
        "        best_f1 = f1_final\n",
        "        best_alpha = alpha\n",
        "\n",
        "print(f'\\nЛучшее значение Alpha: {best_alpha:.1f}')\n",
        "print(f'Лучшая F1-мера: {best_f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b9imFkLtWc8"
      },
      "source": [
        "### 7. Сделайте выводы\n",
        "\n",
        "Запишите в отдельной ячейке текстом выводы о проделанной работе. Для этого ответьте на вопросы:\n",
        "- Какие подходы вы использовали для улучшения работы baseline-моделей?\n",
        "- Какого максимального качества удалось добиться на Test-данных?\n",
        "- Какое при этом получилось качество на отложенной выборке?\n",
        "- Ваша модель переобучилась, недообучилась или обучилась как надо?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Для улучшения моделей использовались методы балансировки классов, радиальное ядро, а также Grid Search для параметров SVC.\n",
        "* Как ни странно, лучше всего себя показала неулучшенная модель логистической регрессии. F1 на отложенной выборке - 0.66.\n",
        "* Модели на отложенной выборке показали более худший результат, чем при обучении, что указывает на их переобучение."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnFjm55atWc-"
      },
      "source": [
        "Важный комментарий! В реальных задачах не следует ожидать, что машинным обучением всегда удастся решить задачу с хорошим качеством. Но использовать все имеющиеся у вас в арсенале методы для достижения наилучшего результата нужно."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
